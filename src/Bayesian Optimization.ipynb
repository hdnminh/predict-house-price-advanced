{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "# import packages for hyperparameters tuning\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../preprocessing_data/preprocessed_train.csv').drop('Id', axis = 1)\n",
    "test_df = pd.read_csv('../preprocessing_data/preprocessed_test.csv').drop('Id', axis = 1)\n",
    "X = np.array(train_df.drop(['SalePrice'], axis = 1).values)\n",
    "y = np.log1p(np.array(train_df['SalePrice'].values))\n",
    "X_test = np.array(test_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size= 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def getRMSLE(model):\n",
    "    \"\"\"\n",
    "    Return the average RMSLE over all folds of training data.\n",
    "    \"\"\"\n",
    "    # Set KFold to shuffle data before the split\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # Get RMSLE score\n",
    "    rmse = np.sqrt(-cross_val_score(\n",
    "        model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=kf))\n",
    "\n",
    "    return rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the k-fold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 XGBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={ 'max_depth': hp.randint('max_depth', 5, 10),\n",
    "        'min_child_weight' : hp.uniform('min_child_weight', 1, 1.5),\n",
    "        'gamma': hp.uniform('gamma', 0, 1),\n",
    "        'subsample': hp.uniform('subsample', 0, 1),\n",
    "        'colsample_bytree' :  hp.uniform('colsample_bytree', 0.5, 1),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.05, 0.3),        \n",
    "        'reg_alpha' : hp.uniform('reg_alpha', 0, 1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0, 1),\n",
    "        'n_estimators': hp.randint('n_estimators', 1000, 3000)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    xgboost = XGBRegressor(seed=0, **params)\n",
    "    xgboost.fit(X_train, y_train)\n",
    "    loss = rmse(y_valid, xgboost.predict(X_valid))\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [08:22<00:00,  5.03s/trial, best loss: 0.12192005941284328]\n",
      "Best hyperparameters: {'colsample_bytree': 0.9781980756358969, 'gamma': 0.13136823018988167, 'learning_rate': 0.05493140226506563, 'max_depth': 8, 'min_child_weight': 1.4783695196881401, 'n_estimators': 2174, 'reg_alpha': 0.17155914762735375, 'reg_lambda': 0.2811705695969712, 'subsample': 0.386800026462253}\n"
     ]
    }
   ],
   "source": [
    "# Optimize\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, \n",
    "            space=space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=100, \n",
    "            trials=trials)\n",
    "\n",
    "print('Best hyperparameters:', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_learning_rate = best\n",
    "best_learning_rate['learning_rate'] = hp.uniform('learning_rate', 0.0001, best['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:48<00:00,  6.48s/trial, best loss: 0.11905596699644086]\n",
      "Best hyperparameters: {'learning_rate': 0.047550847646322746}\n"
     ]
    }
   ],
   "source": [
    "# Optimize\n",
    "trials = Trials()\n",
    "best_learning_rate = fmin(fn=objective, \n",
    "            space=best_learning_rate, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=100, \n",
    "            trials=trials)\n",
    "\n",
    "print('Best hyperparameters:', best_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "best['learning_rate'] = best_learning_rate['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.1317009436603947\n"
     ]
    }
   ],
   "source": [
    "# xgb = XGBRegressor(colsample_bytree=  0.357, gamma=0.0035, learning_rate=0.05, max_depth=4, min_child_weight=5, n_estimators=1419, reg_alpha=0.84, reg_lambda=0.5)\n",
    "xgb = XGBRegressor(**best)\n",
    "xgb.fit(X_train, y_train)\n",
    "ans = pd.read_csv('../submission/cheat.csv').drop('Id', axis = 1)\n",
    "ans = np.array(ans.values).reshape(1, -1)[0]\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(f\"Error: {rmse(np.log1p(ans), y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
